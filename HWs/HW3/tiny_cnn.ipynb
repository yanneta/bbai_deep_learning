{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8d4a0a7",
   "metadata": {},
   "source": [
    "# Homework 3 part a: Build a Tiny CNN on MNIST (Starter)\n",
    "\n",
    "\n",
    "This assignment guides you through building and training a **very small CNN** on **MNIST** using **PyTorch**. It is intentionally minimal and CPU-friendly.\n",
    "\n",
    "**What you'll do:**\n",
    "1) Load a tiny dataset subset\n",
    "2) Write a small CNN (a few convs + linear)\n",
    "3) Train with a simple loop\n",
    "4) Evaluate accuracy & confusion matrix\n",
    "5) Run tiny experiments (channels/kernel size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22cc1ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, math, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e0fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data: MNIST (28x28 grayscale) ===\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "root = \"./data\"\n",
    "train_full = datasets.MNIST(root, train=True, download=True, transform=transform)\n",
    "test_full  = datasets.MNIST(root, train=False, download=True, transform=transform)\n",
    "\n",
    "# Use a small subset for speed\n",
    "train_indices = list(range(0, 10000))       # 10k train samples\n",
    "val_indices   = list(range(10000, 12000))   # 2k val samples from the rest of train\n",
    "test_indices  = list(range(0, 2000))        # 2k test samples\n",
    "\n",
    "train_ds = Subset(train_full, train_indices)\n",
    "val_ds   = Subset(train_full, val_indices)\n",
    "test_ds  = Subset(test_full, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print('Batch:', images.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab046266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Visualize a few samples ===\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "images = images[:8]\n",
    "labels = labels[:8]\n",
    "\n",
    "plt.figure(figsize=(8,2))\n",
    "for i in range(len(images)):\n",
    "    plt.subplot(1, len(images), i+1)\n",
    "    plt.imshow(images[i,0].numpy(), cmap='gray')\n",
    "    plt.title(int(labels[i]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad054226",
   "metadata": {},
   "source": [
    "## Part 1 — Implement a tiny CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be0e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TODO: Define a very small CNN ===\n",
    "# Requirements:\n",
    "# - Input: (N, 1, 28, 28)\n",
    "# - Use 2 Conv2d layers with ReLU, a MaxPool2d, then a Linear head\n",
    "# - Keep it tiny: first conv out_channels ~ 8-16, second ~ 16-32\n",
    "# - Print the number of parameters\n",
    "#\n",
    "# Suggested skeleton:\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, c1=8, c2=16, num_classes=10):\n",
    "        super().__init__()\n",
    "        # TODO: layers (Conv2d, ReLU, MaxPool2d, Linear)\n",
    "        \n",
    "\n",
    "        # After two convs + one pool, feature map shape is (c2, 14, 14)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: forward pass with ReLU and pooling\n",
    "       \n",
    "\n",
    "model = SmallCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3136bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Check shapes ===\n",
    "x, y = next(iter(train_loader))\n",
    "x = x\n",
    "with torch.no_grad():\n",
    "    logits = model(x)\n",
    "print(\"Input:\", x.shape, \"Logits:\", logits.shape)\n",
    "assert logits.shape == (x.shape[0], 10), \"Logits must be [batch, 10]\"\n",
    "print(\"Shape check passed ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451c2c3a",
   "metadata": {},
   "source": [
    "## Part 2 — Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f74f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TODO: Training loop (fill the marked TODOs) ===\n",
    "lr = 1e-2\n",
    "epochs = 5\n",
    "# TODO\n",
    "\n",
    "\n",
    "def accuracy(logits, y):\n",
    "    # TODO \n",
    "\n",
    "def valid_metrics(model, val_loader):\n",
    "    # TODO\n",
    "\n",
    "# TODO\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    running_loss, running_acc, n = 0.0, 0.0, 0\n",
    "    for xb, yb in train_loader:\n",
    "\n",
    "        # --- forward\n",
    "        \n",
    "\n",
    "        # --- backward\n",
    "        \n",
    "       \n",
    "\n",
    "    \n",
    "\n",
    "    # --- validation\n",
    "    \n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | train_acc={train_acc:.4f} | val_acc={val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7fda5c",
   "metadata": {},
   "source": [
    "## Part 3 — Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a9a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Test loss and test accuracy ===\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725f9762",
   "metadata": {},
   "source": [
    "## Mini-Experiments (Answer in Markdown)\n",
    "1. Increase `c1` and `c2` (e.g., `c1=16, c2=32`). What happens to parameter count and accuracy?\\\n",
    "   *Run and report numbers.*\n",
    "2. Change `kernel_size` in conv layers to 5 (with padding=2). Any difference?\\\n",
    "   *Explain briefly.*\n",
    "3. Add `Dropout(p=0.2)` before the linear layer. Does validation accuracy change?\\\n",
    "   *Why might that be?*\n",
    "4. Reduce the training subset to 2,000 samples. How does train vs. val accuracy change?\\\n",
    "   *What does this tell you about capacity and data size?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d6d524",
   "metadata": {},
   "source": [
    "## What to Submit\n",
    "- The completed notebook with all code cells executed.\n",
    "- A short paragraph answering the 4 mini-experiments.\n",
    "- Report final `val_acc` and `test_acc`.\n",
    "\n",
    "## Grading Rubric (10 pts)\n",
    "- (3 pts) Model implemented correctly; shapes & param count shown.\n",
    "- (3 pts) Training loop works; learning curves reasonable; no crashes.\n",
    "- (2 pts) Evaluation + confusion matrix produced.\n",
    "- (2 pts) Mini-experiments: clear, concise answers with evidence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
